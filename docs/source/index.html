<div class="doc-body">
    <section class="hero">
        <div>
            <h1>Take Full Control of Your Data with JAX AI Stacks</h1>
            <a class="button button-primary" href="/">Get started</a>
        </div>
        <img src="./_static/images/hero.svg" class="hero-image">
    </section>
    <section class="three-up">
        <div>
            <h3>Lightweight, flexible, customizable</h3>
            <p>Build AI models without unnecessary overhead. Choose from various libraries like Flax and Optax, or customize your own models and optimizers.</p>
        </div>
        <div>
            <h3>Run anywhere</h3>
            <p>Deploy your AI models wherever you need them. JAX runs across different hardware platforms, from CPUs to GPUs and TPUs, without requiring code changes.</p>
        </div>
        <div>
            <h3>Unopinionated by design</h3>
            <p>Build and structure your projects however you choose. JAX's modular design encourages experimentation, allowing you to integrate with other frameworks and libraries as needed.</p>
        </div>
    </section>
    <section class="banner">
        <h3>What is JAX AI Stacks</h3>
        <p>
            Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Donec odio. Quisque volutpat mattis eros. Nullam malesuada erat ut turpis. Suspendisse urna nibh viverra non semper suscipit posuere a pede. Praesent dapibus neque id cursus faucibus tortor neque egestas auguae eu vulputate magna eros eu erat. Aliquam erat volutpat. Nam dui mi tincidunt quis accumsan porttitor facilisis luctus metus.
        </p>
        <p>
            Donec nec justo eget felis facilisis fermentum. Aliquam porttitor mauris sit amet orci. Aenean dignissim pellentesque felis. Phasellus ultrices nulla quis nibh. Quisque a lectus. Donec consectetuer ligula vulputate sem tristique cursus. Nam nulla quam gravida non commodo a sodales sit amet nisi.
        </p>
        <p>
            Morbi in sem quis dui placerat ornare. Pellentesque odio nisi euismod in pharetra a ultricies in diam. Sed arcu. Cras consequat.
        </p>
    </section>
    <section class="image-section image-right">
        <img src="./_static/images/what-is-the-jax-ai-stack.svg">
        <div class="text-body">
            <h3>What is the JAX AI stack</h3>
            <p>The JAX AI stack provides the tools you need to scale from experimentation to large-scale machine learning. It offers a NumPy-like API while adding automatic differentiation, composable transforms for compilation, and more. You can execute JAX on various hardware platforms, gaining significant performance improvements over NumPy, particularly in data-heavy applications. By leveraging vectorization, code parallelization, and automatic differentiation, JAX optimizes computations. Its ease of use also makes it an excellent tool for rapid prototyping.</p>
        </div>
    </section>
    <section class="image-section">
        <img src="./_static/images/hardware.svg">
        <div class="text-body">
            <h3>Hardware</h3>
            <p>JAX runs efficiently on a variety of hardware, making it easy to scale computations across devices.</p>
            <ul>
                <li>CPU: Suitable for prototyping and smaller-scale tasks.</li>
                <li>GPU: Enables parallel computation for faster training and model execution.</li>
                <li>TPU: Optimized for large-scale machine learning, providing high-speed performance for AI workloads.</li>
            </ul>
            <a class="button button-primary" href="/">Learn more</a>
        </div>
    </section>
    <section class="image-section image-right">
        <img src="./_static/images/compiler.svg">
        <div class="text-body">
            <h3>Compiler / Runtime</h3>
            <p>At the core of JAX's performance is XLA, an advanced linear algebra compiler that optimizes your code.</p>
            <ul>
                <li>XLA Compilation: Converts high-level code into optimized machine code for faster execution.</li>
                <li>Cross-Device Compatibility: Automatically adapts to different hardware (CPU, GPU, TPU) without code changes.</li>
                <li>Memory Optimization: Efficiently handles memory, especially for large models, ensuring smooth execution.</li>
            </ul>
        </div>
    </section>
    <section class="image-section">
        <img src="./_static/images/framework.svg">
        <div class="text-body">
            <h3>Framework</h3>
            <p>JAX is a framework that brings together the ease of Python with advanced program transformations for machine learning.</p>
            <ul>
                <li>NumPy-like API: Use familiar array operations with additional capabilities for high-performance computing.</li>
                <li>Automatic Differentiation: Simplifies gradient-based optimization with grad function, ideal for training models.</li>
                <li>Parallelism and Vectorization: Scale your computations with pmap and vmap, enabling parallel execution across devices.</li>
            </ul>
        </div>
    </section>
    <section class="image-section image-right">
        <img src="./_static/images/core-ai-libraries.svg">
        <div class="text-body">
            <h3>Core AI Libraries</h3>
            <p>JAX is supported by a suite of powerful libraries that streamline AI and machine learning workflows.</p>
            <ul>
                <li>Flax: A flexible library for building and training neural networks.</li>
                <li>tf.data: Optimizes data pipelines for efficient data loading and preprocessing.</li>
                <li>Optax: Provides a range of gradient-based optimizers for model training.</li>
                <li>JetStream: Facilitates model and data parallelism for large-scale computation.</li>
                <li>Orbax: Manages checkpointing and model saving for robust workflow handling.</li>
            </ul>
            <p>AQT: Reduces computational overhead with quantized training, ensuring efficient performance.</p>
        </div>
    </section>
    <section class="image-section">
        <img src="./_static/images/reference-implementation.svg">
        <div class="text-body">
            <h3>Reference Implementation</h3>
            <p>JAX's reference implementations demonstrate the power and flexibility of the stack.</p>
            <ul>
                <li>MaxText: A framework for training large-scale language models, supporting advanced architectures like Gemma, LLAMA2, and Mistral.</li>
                <li>MaxDiffusion: Powers high-quality image generation with Stable Diffusion 2 (SD2) and SDXL, setting a new standard in generative AI.</li>
            </ul>
        </div>
    </section>
</div>